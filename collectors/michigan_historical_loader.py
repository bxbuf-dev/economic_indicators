# collectors/michigan_historical_loader.py
import os
import sys
import pandas as pd
from pathlib import Path

# --- –î–û–ë–ê–í–õ–ï–ù–ò–ï –ö–û–†–ù–ï–í–û–ô –ü–ê–ü–ö–ò –í –ü–£–¢–¨ –ü–û–ò–°–ö–ê –ú–û–î–£–õ–ï–ô ---
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.append(parent_dir)

from dao import IndicatorDAO

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---
INDICATOR_CONFIG = {
    'name': 'umcsi_michigan_full',
    'full_name': 'University of Michigan Consumer Sentiment Survey (Full Data)',
    'source': 'University of Michigan Survey Research Center',
    'description': 'Complete UMCSI data: composite, current conditions, expectations (preliminary & final)'
}

# –ü—É—Ç—å –∫ CSV —Ñ–∞–π–ª—É (–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∫–æ—Ä–Ω—è –ø—Ä–æ–µ–∫—Ç–∞)
CSV_FILE_PATH = 'data/michigan_historical.csv'  # –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–æ–¥ –≤–∞—à –ø—É—Ç—å

def load_historical_data(csv_path):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ Michigan –∏–∑ CSV
    
    –û–∂–∏–¥–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç CSV:
    DATE,COMPOSITE UMCSI,CURRENT,EXPECTATIONS
    01/01/14,81.2,96.8,71.2
    """
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
        if not Path(csv_path).exists():
            print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {csv_path}")
            print("   –£–∫–∞–∂–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –ø—É—Ç—å –∫ CSV —Ñ–∞–π–ª—É —Å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏ Michigan")
            return pd.DataFrame()
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º CSV
        df = pd.read_csv(csv_path)
        print(f"üìÑ –ó–∞–≥—Ä—É–∂–µ–Ω CSV —Ñ–∞–π–ª: {len(df)} —Å—Ç—Ä–æ–∫")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–∂–∏–¥–∞–µ–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        expected_columns = ['DATE', 'COMPOSITE UMCSI', 'CURRENT', 'EXPECTATIONS']
        if not all(col in df.columns for col in expected_columns):
            print(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ CSV: {list(df.columns)}")
            print(f"   –û–∂–∏–¥–∞–µ–º—ã–µ: {expected_columns}")
            return pd.DataFrame()
        
        # –ü–∞—Ä—Å–∏–º –¥–∞—Ç—ã MM/DD/YY -> YYYY-MM-DD
        df['DATE'] = pd.to_datetime(df['DATE'], format='%m/%d/%y')
        
        # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
        df.rename(columns={
            'DATE': 'date',
            'COMPOSITE UMCSI': 'composite',
            'CURRENT': 'current', 
            'EXPECTATIONS': 'expectations'
        }, inplace=True)
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ long format –¥–ª—è —É–¥–æ–±–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ –≤ –ë–î
        long_data = []
        
        for _, row in df.iterrows():
            date_str = row['date'].strftime('%Y-%m-%d')
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞–∂–¥—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—É—é –∑–∞–ø–∏—Å—å
            for category in ['composite', 'current', 'expectations']:
                if pd.notna(row[category]):  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º NaN –∑–Ω–∞—á–µ–Ω–∏—è
                    long_data.append({
                        'date': date_str,
                        'category': category,  # –ë–µ–∑ —Å—É—Ñ—Ñ–∏–∫—Å–∞ _p –¥–ª—è –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
                        'value': float(row[category])
                    })
        
        result_df = pd.DataFrame(long_data)
        print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(result_df)} –∑–∞–ø–∏—Å–µ–π –≤ long format")
        
        return result_df
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ CSV: {e}")
        return pd.DataFrame()

def main():
    """
    –û–¥–Ω–æ—Ä–∞–∑–æ–≤—ã–π –∑–∞–≥—Ä—É–∑—á–∏–∫ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö Michigan UMCSI
    """
    dao = None
    try:
        print("--- –ó–ê–ì–†–£–ó–ß–ò–ö –ò–°–¢–û–†–ò–ß–ï–°–ö–ò–• –î–ê–ù–ù–´–• MICHIGAN UMCSI ---")
        
        # –ü—É—Ç—å –∫ CSV —Ñ–∞–π–ª—É
        project_root = Path(__file__).parent.parent
        csv_path = project_root / CSV_FILE_PATH
        
        print(f"üîç –ü–æ–∏—Å–∫ CSV —Ñ–∞–π–ª–∞: {csv_path}")
        
        # –ï—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ—Å–∏–º —É–∫–∞–∑–∞—Ç—å –ø—É—Ç—å
        if not csv_path.exists():
            print("\nüìù –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω. –í–≤–µ–¥–∏—Ç–µ –ø—É—Ç—å –∫ CSV —Ñ–∞–π–ª—É —Å –¥–∞–Ω–Ω—ã–º–∏ Michigan:")
            user_path = input("–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É: ").strip()
            if user_path:
                csv_path = Path(user_path)
            else:
                print("‚ùå –ü—É—Ç—å –Ω–µ —É–∫–∞–∑–∞–Ω. –í—ã—Ö–æ–¥.")
                return
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        historical_df = load_historical_data(csv_path)
        
        if historical_df.empty:
            print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏")
            return
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º DAO –∏ –¥–æ–±–∞–≤–ª—è–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä
        dao = IndicatorDAO()
        indicator_id = dao.add_indicator(**INDICATOR_CONFIG)
        
        if not indicator_id:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä")
            return
        
        print(f"‚úÖ –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä —Å–æ–∑–¥–∞–Ω —Å ID: {indicator_id}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ –¥–∞–Ω–Ω—ã–µ –≤ –ë–î
        existing_date = dao.get_latest_indicator_date(indicator_id)
        if existing_date:
            print(f"‚ö†Ô∏è  –í –ë–î —É–∂–µ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–æ {existing_date}")
            confirm = input("–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –∑–∞–≥—Ä—É–∑–∫—É? (y/N): ").strip().lower()
            if confirm not in ['y', 'yes', '–¥', '–¥–∞']:
                print("‚ùå –ó–∞–≥—Ä—É–∑–∫–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞")
                return
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ –ë–î
        print(f"üíæ –ó–∞–≥—Ä—É–∑–∫–∞ {len(historical_df)} –∑–∞–ø–∏—Å–µ–π –≤ –ë–î...")
        
        success_count = 0
        for _, row in historical_df.iterrows():
            dao.add_indicator_value(
                indicator_id=indicator_id,
                date=row['date'],
                value=row['value'],
                category=row['category']
            )
            success_count += 1
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 100 –∑–∞–ø–∏—Å–µ–π
            if success_count % 100 == 0:
                print(f"   –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {success_count}/{len(historical_df)}")
        
        print(f"üéâ –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!")
        print(f"   –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {success_count}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –ø–µ—Ä–∏–æ–¥—É
        min_date = historical_df['date'].min()
        max_date = historical_df['date'].max()
        print(f"   –ü–µ—Ä–∏–æ–¥: {min_date} - {max_date}")
        
        categories = historical_df['category'].unique()
        print(f"   –ö–∞—Ç–µ–≥–æ—Ä–∏–∏: {', '.join(categories)}")

    except Exception as e:
        print(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}")
    finally:
        if dao:
            dao.close()
            print("üîå –°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö –∑–∞–∫—Ä—ã—Ç–æ.")

if __name__ == "__main__":
    main()